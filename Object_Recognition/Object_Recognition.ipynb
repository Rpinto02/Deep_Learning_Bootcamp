{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "test_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/cifar_image_flattened_pixels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 1), array([6], dtype=uint8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train)),len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313725, 0.24705882],\n",
       "        [0.16862745, 0.18039216, 0.17647059],\n",
       "        [0.19607843, 0.18823529, 0.16862745],\n",
       "        ...,\n",
       "        [0.61960784, 0.51764706, 0.42352941],\n",
       "        [0.59607843, 0.49019608, 0.4       ],\n",
       "        [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843137, 0.07843137],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509804, 0.21568627],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215686, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941176, 0.19607843],\n",
       "        [0.47058824, 0.32941176, 0.19607843],\n",
       "        [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.81568627, 0.66666667, 0.37647059],\n",
       "        [0.78823529, 0.6       , 0.13333333],\n",
       "        [0.77647059, 0.63137255, 0.10196078],\n",
       "        ...,\n",
       "        [0.62745098, 0.52156863, 0.2745098 ],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "       [[0.70588235, 0.54509804, 0.37647059],\n",
       "        [0.67843137, 0.48235294, 0.16470588],\n",
       "        [0.72941176, 0.56470588, 0.11764706],\n",
       "        ...,\n",
       "        [0.72156863, 0.58039216, 0.36862745],\n",
       "        [0.38039216, 0.24313725, 0.13333333],\n",
       "        [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "       [[0.69411765, 0.56470588, 0.45490196],\n",
       "        [0.65882353, 0.50588235, 0.36862745],\n",
       "        [0.70196078, 0.55686275, 0.34117647],\n",
       "        ...,\n",
       "        [0.84705882, 0.72156863, 0.54901961],\n",
       "        [0.59215686, 0.4627451 , 0.32941176],\n",
       "        [0.48235294, 0.36078431, 0.28235294]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizing the pixel values\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "#using the CIFAR-10 example\n",
    "batch_size = 32\n",
    "steps_per_epoch= len(x_train)/batch_size\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "#num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_object_recognition_model.h5'\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create a data generation with the train truth images and dataframe\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 268s 172ms/step - loss: 1.8638 - accuracy: 0.3073 - val_loss: 2.2920 - val_accuracy: 0.1476\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 268s 171ms/step - loss: 1.6328 - accuracy: 0.4015 - val_loss: 2.5435 - val_accuracy: 0.1354\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 267s 171ms/step - loss: 1.5327 - accuracy: 0.4424 - val_loss: 2.7149 - val_accuracy: 0.1519\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 268s 171ms/step - loss: 1.4628 - accuracy: 0.4703 - val_loss: 2.6438 - val_accuracy: 0.1765\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 267s 171ms/step - loss: 1.4093 - accuracy: 0.4915 - val_loss: 2.5296 - val_accuracy: 0.1797\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 268s 171ms/step - loss: 1.3667 - accuracy: 0.5086 - val_loss: 2.5915 - val_accuracy: 0.1852\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 1.3297 - accuracy: 0.5227 - val_loss: 2.5281 - val_accuracy: 0.2165\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 1.2928 - accuracy: 0.5360 - val_loss: 2.7260 - val_accuracy: 0.1940\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 268s 171ms/step - loss: 1.2584 - accuracy: 0.5513 - val_loss: 2.5285 - val_accuracy: 0.2332\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 268s 172ms/step - loss: 1.2316 - accuracy: 0.5612 - val_loss: 2.3625 - val_accuracy: 0.2748\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 276s 176ms/step - loss: 1.2115 - accuracy: 0.5683 - val_loss: 2.4472 - val_accuracy: 0.2799\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 1.1905 - accuracy: 0.5765 - val_loss: 2.4581 - val_accuracy: 0.2461\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 277s 177ms/step - loss: 1.1722 - accuracy: 0.5848 - val_loss: 2.4780 - val_accuracy: 0.2773\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.1548 - accuracy: 0.5913 - val_loss: 2.2110 - val_accuracy: 0.3162\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.1352 - accuracy: 0.5985 - val_loss: 2.4499 - val_accuracy: 0.2702\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.1273 - accuracy: 0.6012 - val_loss: 2.3253 - val_accuracy: 0.3256\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.1109 - accuracy: 0.6072 - val_loss: 2.5020 - val_accuracy: 0.2634\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0983 - accuracy: 0.6152 - val_loss: 2.4177 - val_accuracy: 0.2805\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0877 - accuracy: 0.6168 - val_loss: 2.2429 - val_accuracy: 0.3330\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 1.0767 - accuracy: 0.6217 - val_loss: 2.4124 - val_accuracy: 0.2938\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 271s 174ms/step - loss: 1.0704 - accuracy: 0.6247 - val_loss: 2.3416 - val_accuracy: 0.2855\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0627 - accuracy: 0.6283 - val_loss: 2.3155 - val_accuracy: 0.2883\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0569 - accuracy: 0.6304 - val_loss: 2.4037 - val_accuracy: 0.3047\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0513 - accuracy: 0.6329 - val_loss: 2.0982 - val_accuracy: 0.3321\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.0424 - accuracy: 0.6374 - val_loss: 2.3221 - val_accuracy: 0.3185\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0411 - accuracy: 0.6359 - val_loss: 2.3604 - val_accuracy: 0.3186\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0324 - accuracy: 0.6409 - val_loss: 2.2680 - val_accuracy: 0.3252\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0362 - accuracy: 0.6414 - val_loss: 2.1969 - val_accuracy: 0.3183\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 271s 174ms/step - loss: 1.0265 - accuracy: 0.6440 - val_loss: 2.3897 - val_accuracy: 0.3296\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.0229 - accuracy: 0.6448 - val_loss: 2.4605 - val_accuracy: 0.3331\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0232 - accuracy: 0.6458 - val_loss: 2.1105 - val_accuracy: 0.3323\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 1.0136 - accuracy: 0.6497 - val_loss: 2.2074 - val_accuracy: 0.3228\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 1.0137 - accuracy: 0.6492 - val_loss: 2.1713 - val_accuracy: 0.3362\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.0085 - accuracy: 0.6519 - val_loss: 2.1442 - val_accuracy: 0.3390\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 1.0039 - accuracy: 0.6532 - val_loss: 2.1098 - val_accuracy: 0.3414\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 1.0065 - accuracy: 0.6528 - val_loss: 2.3816 - val_accuracy: 0.3306\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 0.9948 - accuracy: 0.6556 - val_loss: 2.1348 - val_accuracy: 0.3487\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9960 - accuracy: 0.6570 - val_loss: 2.3183 - val_accuracy: 0.2967\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 270s 173ms/step - loss: 0.9993 - accuracy: 0.6532 - val_loss: 2.3141 - val_accuracy: 0.2766\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 1.0005 - accuracy: 0.6569 - val_loss: 2.1208 - val_accuracy: 0.3111\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 269s 172ms/step - loss: 0.9977 - accuracy: 0.6601 - val_loss: 2.1883 - val_accuracy: 0.2996\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 270s 172ms/step - loss: 0.9949 - accuracy: 0.6595 - val_loss: 2.0596 - val_accuracy: 0.3576\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9977 - accuracy: 0.6576 - val_loss: 2.5679 - val_accuracy: 0.2434\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9993 - accuracy: 0.6566 - val_loss: 2.2122 - val_accuracy: 0.2977\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 273s 175ms/step - loss: 0.9978 - accuracy: 0.6591 - val_loss: 2.0396 - val_accuracy: 0.3494\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 271s 173ms/step - loss: 0.9923 - accuracy: 0.6614 - val_loss: 2.1896 - val_accuracy: 0.3392\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9892 - accuracy: 0.6611 - val_loss: 2.6034 - val_accuracy: 0.2590\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9921 - accuracy: 0.6609 - val_loss: 2.4984 - val_accuracy: 0.2761\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 273s 174ms/step - loss: 0.9900 - accuracy: 0.6618 - val_loss: 2.7383 - val_accuracy: 0.2701\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 272s 174ms/step - loss: 0.9890 - accuracy: 0.6614 - val_loss: 2.2256 - val_accuracy: 0.3034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecaa8a25b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at c:\\DPHi\\Deep_Learning_Bootcamp\\saved_models\\keras_object_recognition_model.h5 \n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3072)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>106</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>107</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>176</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>168</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>109</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>104</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>103</td>\n",
       "      <td>100</td>\n",
       "      <td>109</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>115</td>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>172</td>\n",
       "      <td>193</td>\n",
       "      <td>136</td>\n",
       "      <td>173</td>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>179</td>\n",
       "      <td>192</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>215</td>\n",
       "      <td>214</td>\n",
       "      <td>218</td>\n",
       "      <td>220</td>\n",
       "      <td>218</td>\n",
       "      <td>226</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>209</td>\n",
       "      <td>201</td>\n",
       "      <td>204</td>\n",
       "      <td>216</td>\n",
       "      <td>203</td>\n",
       "      <td>201</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>74</td>\n",
       "      <td>144</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>139</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>139</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>41</td>\n",
       "      <td>77</td>\n",
       "      <td>130</td>\n",
       "      <td>44</td>\n",
       "      <td>75</td>\n",
       "      <td>133</td>\n",
       "      <td>42</td>\n",
       "      <td>73</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>156</td>\n",
       "      <td>186</td>\n",
       "      <td>205</td>\n",
       "      <td>153</td>\n",
       "      <td>183</td>\n",
       "      <td>201</td>\n",
       "      <td>153</td>\n",
       "      <td>183</td>\n",
       "      <td>201</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>49</td>\n",
       "      <td>79</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>77</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>68</td>\n",
       "      <td>101</td>\n",
       "      <td>169</td>\n",
       "      <td>69</td>\n",
       "      <td>103</td>\n",
       "      <td>173</td>\n",
       "      <td>70</td>\n",
       "      <td>104</td>\n",
       "      <td>176</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>216</td>\n",
       "      <td>190</td>\n",
       "      <td>168</td>\n",
       "      <td>219</td>\n",
       "      <td>193</td>\n",
       "      <td>169</td>\n",
       "      <td>214</td>\n",
       "      <td>189</td>\n",
       "      <td>163</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>182</td>\n",
       "      <td>167</td>\n",
       "      <td>150</td>\n",
       "      <td>184</td>\n",
       "      <td>170</td>\n",
       "      <td>152</td>\n",
       "      <td>188</td>\n",
       "      <td>171</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>102</td>\n",
       "      <td>134</td>\n",
       "      <td>146</td>\n",
       "      <td>100</td>\n",
       "      <td>131</td>\n",
       "      <td>145</td>\n",
       "      <td>99</td>\n",
       "      <td>130</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>129</td>\n",
       "      <td>141</td>\n",
       "      <td>127</td>\n",
       "      <td>103</td>\n",
       "      <td>118</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  3062  3063  3064  \\\n",
       "0      98  105  108   92  101  106   91  101  107   93  ...   171   183   182   \n",
       "1     101  108  101  101  108  101  102  109  102  103  ...   103   100   109   \n",
       "2      85  115   27   63   90   25   37   66   15   69  ...   141   172   193   \n",
       "3     213  213  214  215  214  218  220  218  226  223  ...   216   193   194   \n",
       "4      41   74  144   41   75  139   41   75  139   41  ...   133    41    77   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "1995  156  186  205  153  183  201  153  183  201  152  ...    90    40    73   \n",
       "1996   68  101  169   69  103  173   70  104  176   71  ...    58    61    73   \n",
       "1997  216  190  168  219  193  169  214  189  163  188  ...   135   182   167   \n",
       "1998   46   24   17   43   32   11   77   82   60  117  ...   147   102   134   \n",
       "1999   55   74   67   64   87   82   44   73   69   85  ...    41    79    85   \n",
       "\n",
       "      3065  3066  3067  3068  3069  3070  3071  \n",
       "0      176   175   175   168   181   181   175  \n",
       "1      104   100   109   103   100   109   102  \n",
       "2      136   173   192   138   179   192   149  \n",
       "3      209   201   204   216   203   201   237  \n",
       "4      130    44    75   133    42    73   144  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "1995    92    49    79    99    46    77    97  \n",
       "1996    64    51    62    53    49    61    52  \n",
       "1997   150   184   170   152   188   171   151  \n",
       "1998   146   100   131   145    99   130   148  \n",
       "1999    73   129   141   127   103   118   103  \n",
       "\n",
       "[2000 rows x 3072 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = test_data\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data = teste.astype('float32')\n",
    "x_test_data /= 255\n",
    "df = x_test_data.rename_axis('ID').values\n",
    "dff = df.reshape(2000,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13061044, 0.01076612, 0.25867403, 0.1555994 , 0.10574258,\n",
       "       0.09053725, 0.13180049, 0.02097947, 0.08185315, 0.01343709],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130610</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.258674</td>\n",
       "      <td>0.155599</td>\n",
       "      <td>0.105743</td>\n",
       "      <td>0.090537</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.081853</td>\n",
       "      <td>0.013437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097752</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.215435</td>\n",
       "      <td>0.224033</td>\n",
       "      <td>0.122739</td>\n",
       "      <td>0.112313</td>\n",
       "      <td>0.121279</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.080696</td>\n",
       "      <td>0.007646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065391</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.153710</td>\n",
       "      <td>0.073965</td>\n",
       "      <td>0.406731</td>\n",
       "      <td>0.070645</td>\n",
       "      <td>0.087529</td>\n",
       "      <td>0.075747</td>\n",
       "      <td>0.045696</td>\n",
       "      <td>0.014817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118839</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.102493</td>\n",
       "      <td>0.063977</td>\n",
       "      <td>0.096723</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>0.565055</td>\n",
       "      <td>0.006411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146034</td>\n",
       "      <td>0.007476</td>\n",
       "      <td>0.164659</td>\n",
       "      <td>0.191601</td>\n",
       "      <td>0.070680</td>\n",
       "      <td>0.132827</td>\n",
       "      <td>0.087526</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.160581</td>\n",
       "      <td>0.016618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.058980</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.054461</td>\n",
       "      <td>0.068549</td>\n",
       "      <td>0.199417</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.571122</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.042016</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.091384</td>\n",
       "      <td>0.486721</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>0.023021</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.070605</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.283826</td>\n",
       "      <td>0.322275</td>\n",
       "      <td>0.078133</td>\n",
       "      <td>0.108058</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.037937</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.022841</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.134470</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.039903</td>\n",
       "      <td>0.326474</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.015697</td>\n",
       "      <td>0.002544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.118720</td>\n",
       "      <td>0.057027</td>\n",
       "      <td>0.617824</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.162221</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.130610  0.010766  0.258674  0.155599  0.105743  0.090537  0.131800   \n",
       "1     0.097752  0.005543  0.215435  0.224033  0.122739  0.112313  0.121279   \n",
       "2     0.065391  0.005768  0.153710  0.073965  0.406731  0.070645  0.087529   \n",
       "3     0.118839  0.001871  0.102493  0.063977  0.096723  0.022401  0.015308   \n",
       "4     0.146034  0.007476  0.164659  0.191601  0.070680  0.132827  0.087526   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.058980  0.000491  0.054461  0.068549  0.199417  0.023579  0.015845   \n",
       "1996  0.042016  0.000280  0.215710  0.091384  0.486721  0.021767  0.023021   \n",
       "1997  0.070605  0.000612  0.283826  0.322275  0.078133  0.108058  0.094500   \n",
       "1998  0.022841  0.000650  0.134470  0.426901  0.039903  0.326474  0.021346   \n",
       "1999  0.003497  0.000251  0.118720  0.057027  0.617824  0.018614  0.162221   \n",
       "\n",
       "             7         8         9  \n",
       "0     0.020979  0.081853  0.013437  \n",
       "1     0.012563  0.080696  0.007646  \n",
       "2     0.075747  0.045696  0.014817  \n",
       "3     0.006922  0.565055  0.006411  \n",
       "4     0.021997  0.160581  0.016618  \n",
       "...        ...       ...       ...  \n",
       "1995  0.004382  0.571122  0.003175  \n",
       "1996  0.010294  0.107675  0.001134  \n",
       "1997  0.002115  0.037937  0.001939  \n",
       "1998  0.009174  0.015697  0.002544  \n",
       "1999  0.013290  0.007392  0.001163  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = []\n",
    "for i in range (0,len(predictions)):\n",
    "    submission.append(np.argmax(predictions[i]))\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(submission)\n",
    "res.index = test_data.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "res.columns = [\"prediction\"]\n",
    "res.to_csv(\"prediction_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "0              2\n",
       "1              3\n",
       "2              4\n",
       "3              8\n",
       "4              3\n",
       "...          ...\n",
       "1995           8\n",
       "1996           4\n",
       "1997           3\n",
       "1998           3\n",
       "1999           4\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
